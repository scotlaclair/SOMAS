# SOMAS Configuration
# @copilot-context: Main configuration for Self-Sovereign Orchestrated Multi-Agent System
# This file defines the 7-stage pipeline, AI agent providers, and optimization settings
# @copilot-review: Verify security settings when modifying agent configurations

version: "1.0.0"
name: "Self-Sovereign Orchestrated Multi-Agent System"
description: "Configuration for AI-driven software development pipeline"

# Pipeline Stages

pipeline:
  stages:
    - id: "ideation"
      order: 1
      enabled: true
      agent: "planner"
      human_gate: false
      auto_proceed: true
      timeout_hours: 2
      
    - id: "specification"
      order: 2
      enabled: true
      agent: "specifier"
      human_gate: false  # CHANGED: No longer requires human approval
      auto_proceed: true
      timeout_hours: 24
      
    - id: "simulation"
      order: 3
      enabled: true
      agent: "simulator"
      human_gate: false
      auto_proceed: true
      timeout_hours: 2
      
    - id: "architecture"
      order: 4
      enabled: true
      agent: "architect"
      human_gate: false
      auto_proceed: true
      timeout_hours: 12
      
    - id: "implementation"
      order: 5
      enabled: true
      agent: "coder"
      human_gate: false
      auto_proceed: true
      timeout_hours: 48
      
    - id: "validation"
      order: 6
      enabled: true
      agent: "validator"
      human_gate: false
      auto_proceed: true
      timeout_hours: 12
      max_retries: 3  # Auto-retry validation failures up to 3 times
      
    - id: "staging"
      order: 7
      enabled: true
      agent: "deployer"
      human_gate: true  # ONLY stage requiring human approval
      auto_proceed: false
      human_action: "merge_approval"
      timeout_hours: 24

# Agent Configuration
# @copilot-delegate: Agent configurations define AI provider mappings
# Updated 2026 Frontier Tier models for optimal performance:
# - GPT-5.2-Codex: SOTA coding agent for implementation
# - Claude Opus 4.5: Deepest reasoning for architecture
# - Claude Sonnet 4.5: Balanced power for code review and testing
# - GPT-5.2: General intelligence for requirements and security
# - Gemini 3 Pro: Multimodal & long context for documentation
# - Grok Code Fast 1: Low latency for orchestration

agents:
  providers:
    # Specialized Codex models for implementation
    gpt_5_2_codex:
      model: "gpt-5.2-codex"
      temperature: 0.3
      max_tokens: 8000
      description: "SOTA coding agent optimized for agentic loops"
      
    gpt_5_1_codex:
      model: "gpt-5.1-codex"
      temperature: 0.3
      max_tokens: 8000
      description: "Stable implementation agent"
      
    gpt_5_1_codex_max:
      model: "gpt-5.1-codex-max"
      temperature: 0.3
      max_tokens: 16000
      description: "Massive context for large-scale refactors"
      
    # Claude Opus models for deep reasoning
    claude_opus_4_5:
      model: "claude-opus-4.5"
      temperature: 0.7
      max_tokens: 8000
      description: "Deepest reasoning for architecture and design"
      
    claude_opus_4_1:
      model: "claude-opus-4.1"
      temperature: 0.7
      max_tokens: 8000
      description: "High reasoning for reviews"
      
    # Claude Sonnet models for balanced tasks
    claude_sonnet_4_5:
      model: "claude-sonnet-4.5"
      temperature: 0.5
      max_tokens: 8000
      description: "Balanced power for testing and review"
      
    claude_haiku_4_5:
      model: "claude-haiku-4.5"
      temperature: 0.4
      max_tokens: 4000
      description: "Smart and fast for debugging"
      
    # GPT-5 series for general intelligence
    gpt_5_2:
      model: "gpt-5.2"
      temperature: 0.7
      max_tokens: 8000
      description: "Best all-rounder for requirements and security"
      
    gpt_5_1:
      model: "gpt-5.1"
      temperature: 0.7
      max_tokens: 8000
      description: "Standard intelligence for general tasks"
      
    gpt_5_mini:
      model: "gpt-5-mini"
      temperature: 0.4
      max_tokens: 4000
      description: "Efficient reasoning for simple logic"
      
    # Gemini models for multimodal and long context
    gemini_3_pro:
      model: "gemini-3-pro"
      temperature: 0.5
      max_tokens: 32000
      description: "Multimodal & long context for comprehensive documentation"
      
    gemini_2_5_pro:
      model: "gemini-2.5-pro"
      temperature: 0.5
      max_tokens: 16000
      description: "Legacy long-context librarian"
      
    gemini_3_flash:
      model: "gemini-3-flash"
      temperature: 0.4
      max_tokens: 8000
      description: "High volume data processing"
      
    # Grok for speed
    grok_code_fast_1:
      model: "grok-code-fast-1"
      temperature: 0.3
      max_tokens: 4000
      description: "Lowest latency for orchestration and routing"
      
    # Legacy models (kept for fallback)
    codex:
      model: "gpt-4"
      temperature: 0.7
      max_tokens: 4000
      description: "Legacy fallback"
      
    gemini:
      model: "gemini-pro"
      temperature: 0.5
      max_tokens: 8000
      description: "Legacy fallback"
      
    copilot:
      model: "gpt-4"
      temperature: 0.3
      max_tokens: 4000
      description: "Legacy fallback"
      
  agent_configs:
    planner:
      provider: "gpt_5_2"
      config_file: ".somas/agents/planner.yml"
      description: "Requirements analysis with general intelligence"
      
    specifier:
      provider: "gpt_5_2"
      config_file: ".somas/agents/specifier.yml"
      description: "Specification with general intelligence"
      
    simulator:
      provider: "gpt_5_2"
      config_file: ".somas/agents/simulator.yml"
      description: "Simulation planning with general intelligence"
      
    architect:
      provider: "claude_opus_4_5"
      config_file: ".somas/agents/architect.yml"
      description: "System design with deepest reasoning"
      
    implementer:
      provider: "gpt_5_2_codex"
      config_file: ".somas/agents/implementer.yml"
      description: "Code generation with SOTA coding agent"
      
    coder:
      provider: "gpt_5_2_codex"
      config_file: ".somas/agents/coder.yml"
      description: "Code generation with SOTA coding agent"
      
    reviewer:
      provider: "claude_sonnet_4_5"
      config_file: ".somas/agents/reviewer.yml"
      description: "Code review with balanced power"
      
    security:
      provider: "gpt_5_2"
      config_file: ".somas/agents/security.yml"
      description: "Security analysis with adversarial creativity"
      
    tester:
      provider: "claude_sonnet_4_5"
      config_file: ".somas/agents/tester.yml"
      description: "Testing with balanced power"
      
    documenter:
      provider: "gemini_3_pro"
      config_file: ".somas/agents/documenter.yml"
      description: "Documentation with massive context window"
      
    orchestrator:
      provider: "grok_code_fast_1"
      config_file: ".somas/agents/orchestrator.yml"
      description: "Pipeline coordination with low latency"
      
    validator:
      provider: "claude_sonnet_4_5"
      config_file: ".somas/agents/validator.yml"
      description: "Validation with balanced power"
      
    deployer:
      provider: "claude_opus_4_5"
      config_file: ".somas/agents/deployer.yml"
      description: "Deployment planning with deep reasoning"

# Optimization Configuration

optimization:
  simulation:
    enabled: true
    method: "monte_carlo"
    iterations: 1000
    confidence_interval: 0.90
    rerun_on_spec_change: true
    save_intermediate_results: true
    
  parallelization:
    enabled: true
    max_concurrent_tasks: 5
    respect_dependencies: true
    load_balancing_strategy: "duration_based"
    
  adaptive_sizing:
    enabled: true
    target_task_duration_minutes: 240  # 4 hours
    max_task_duration_minutes: 480    # 8 hours
    min_task_duration_minutes: 60     # 1 hour
    max_lines_per_task: 100
    auto_decompose: true
    decomposition_strategy: "feature_boundary"
    
  task_prioritization:
    enabled: true
    strategy: "critical_path_first"
    consider_risk: true
    consider_dependencies: true
    
  risk_multipliers:
    external_dependencies: 1.5
    new_technology: 2.0
    high_complexity: 1.8
    integration_heavy: 1.7

# Project Management Integration

project_management:
  enabled: true
  
  github_project:
    create_per_pipeline: true
    template: "SOMAS Pipeline"
    template_file: ".github/project-template.yml"
    auto_archive_on_completion: false
    
    # Note: Column definitions are in .github/project-template.yml to maintain single source of truth
        
    task_decomposition:
      create_issues_for: "each_component"
      link_to_parent: true
      auto_assign_labels: true
      assign_from_execution_plan: true
      
    metrics_tracked:
      - "time_in_stage"
      - "iteration_count"
      - "blocker_duration"
      - "human_wait_time"
      - "estimation_accuracy"
      
  notifications:
    enabled: true
    channels:
      - "github_issue_comments"
      - "github_notifications"
    
    notify_on:
      - "stage_completed"
      - "human_gate_opened"
      - "error_occurred"
      - "pipeline_completed"
      - "high_risk_task_started"
    
    mention_owner: true
    owner: "@scotlaclair"

# Analytics & Learning

analytics:
  enabled: true
  storage: ".somas/analytics/runs/"
  schema_file: ".somas/analytics/schema.yml"
  retention_days: 90
  
  track:
    - "task_duration_vs_estimate"
    - "iteration_count_by_task_type"
    - "parallel_efficiency"
    - "critical_path_accuracy"
    - "human_intervention_frequency"
    
  export:
    enabled: true
    formats: ["json", "csv"]
    schedule: "weekly"
    
  dashboards:
    enabled: false  # Enable when visualization is implemented
    update_frequency: "hourly"

learning:
  enabled: true
  record_all_runs: true
  update_estimates_from_actuals: true
  pattern_extraction: true
  
  models:
    duration_estimation:
      enabled: true
      algorithm: "gradient_boosting"
      min_training_samples: 50
      retrain_frequency: "weekly"
      
    critical_path_prediction:
      enabled: true
      algorithm: "random_forest"
      min_training_samples: 100
      retrain_frequency: "weekly"
      
  feedback_loop:
    enabled: true
    incorporate_human_feedback: true
    adjust_risk_thresholds: true
    update_decomposition_rules: true

# Quality Gates

quality_gates:
  specification:
    - "All requirements have unique IDs"
    - "All requirements are testable"
    - "No ambiguous language (TBD, maybe, etc.)"
    - "Open questions resolved or escalated"
    - "Security requirements defined"
    
  simulation:
    - "Task graph is acyclic"
    - "All tasks have duration estimates"
    - "Critical path identified"
    - "Parallelization opportunities documented"
    
  architecture:
    - "All components defined"
    - "Interfaces specified"
    - "Data flows documented"
    - "Technology choices justified"
    
  implementation:
    - "All tests passing"
    - "Code coverage > 80%"
    - "No critical security vulnerabilities"
    - "Documentation complete"
    
  validation:
    - "All acceptance criteria met"
    - "Performance requirements satisfied"
    - "Security scan passed"
    - "Integration tests passing"

# Artifact Management

artifacts:
  storage: "projects/{project_id}/artifacts/"
  
  types:
    specification:
      - "SPEC.md"
      - "requirements.yml"
      
    simulation:
      - "execution_plan.yml"
      - "task_graph.yml"
      - "simulation_results.json"
      
    architecture:
      - "ARCHITECTURE.md"
      - "api_specs.yml"
      - "data_models.yml"
      
    implementation:
      - "source_code/"
      - "tests/"
      - "documentation/"
      
    validation:
      - "test_results.json"
      - "coverage_report.html"
      - "security_scan.json"
      
  retention:
    active_projects: "indefinite"
    completed_projects: 365  # days
    failed_projects: 180  # days
    
  versioning:
    enabled: true
    strategy: "git_based"

# Security

security:
  secrets_management:
    provider: "github_secrets"
    required_secrets:
      - "GITHUB_TOKEN"
      - "AI_API_KEY"
      
  code_scanning:
    enabled: true
    tools:
      - "codeql"
      - "dependabot"
      
  vulnerability_management:
    fail_on_critical: true
    auto_fix_enabled: true
    
  access_control:
    require_approval_for:
      - "specification"
      - "staging"
    approvers:
      - "@scotlaclair"
      # Note: Consider using GitHub teams for better team management:
      # - "@org-name/approvers-team"
      # This avoids hardcoding individual usernames

# Error Handling

error_handling:
  retry_strategy:
    max_attempts: 3
    backoff_strategy: "exponential"
    base_delay_seconds: 60
    
  fallback_agents:
    gpt_5_2_codex: "gpt_5_1_codex"
    gpt_5_1_codex: "claude_opus_4_5"
    claude_opus_4_5: "claude_opus_4_1"
    claude_opus_4_1: "gpt_5_2"
    claude_sonnet_4_5: "claude_haiku_4_5"
    gpt_5_2: "gpt_5_1"
    gemini_3_pro: "gemini_2_5_pro"
    grok_code_fast_1: "gpt_5_mini"
    # Legacy fallbacks
    codex: "gemini"
    gemini: "copilot"
    
  escalation:
    enabled: true
    notify_on_failure: true
    create_issue_on_failure: true

# Monitoring

monitoring:
  health_checks:
    enabled: true
    interval_minutes: 5
    
  metrics:
    - "pipeline_duration"
    - "stage_duration"
    - "task_duration"
    - "error_rate"
    - "human_intervention_rate"
    
  alerts:
    enabled: true
    thresholds:
      pipeline_duration_hours: 168  # 1 week
      error_rate_percent: 20
      human_wait_time_hours: 48

# Development

development:
  debug_mode: false
  verbose_logging: true
  save_intermediate_states: true
  
  testing:
    dry_run_mode: false
    mock_ai_responses: false
    skip_human_gates: false

# Documentation

documentation:
  auto_generate: true
  formats:
    - "markdown"
    - "html"
    
  include:
    - "pipeline_overview"
    - "agent_descriptions"
    - "quality_gates"
    - "optimization_results"
    
  output_path: "docs/somas/"
